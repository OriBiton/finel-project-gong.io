#!/usr/bin/env python
# coding: utf-8

# In[1]:

import streamlit as st
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier, VotingClassifier, VotingRegressor
from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.metrics import mean_squared_error, accuracy_score, roc_auc_score, r2_score
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from xgboost import XGBRegressor, XGBClassifier
from lightgbm import LGBMClassifier, LGBMRegressor
import numpy as np
import pandas as pd

def detect_problem_type(target_column):
    """
     转 住 注:
    - 住:  砖 住驻专  砖 注专 ,   专爪驻 (  注 住拽)
    - 专专住:  砖 转专 -10 注专 ,   专 转 专爪驻.
    -  住专转:  注专 注 住专 (ordinal)  .
    - 住 专:  注专  0 -1 .
    """
    
    unique_values = target_column.unique()
    num_unique = len(unique_values)
    
    #  注专  0 -1 , 砖 转  注 砖 住 专
    if set(unique_values) == {0, 1}:
        return "classification"
    
    # 拽  注专  专爪驻 ( 砖 转 住驻专  注专?)
    if np.issubdtype(target_column.dtype, np.number) :
        return "regression"  #  专 住驻专 专爪驻,  专专住
     
    #  砖 注专 拽专 专,  住
    else:
        return "classification"


import streamlit as st
import shap
import pandas as pd
from sklearn.metrics import accuracy_score, mean_squared_error

def build_and_train_model(X, y, problem_type):
    """
     ,  转, 爪 注 住专 专 转   转专.
    """
    st.write(" Detecting Problem Type...")
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    best_model = None
    best_score = None
    best_model_name = ""
    st.write(f" Problem type detected: **{problem_type}**")
    
    if problem_type == "regression":
        models = {
            "LinearRegression": LinearRegression(),
            "DecisionTreeRegressor": DecisionTreeRegressor(),
            "RandomForestRegressor": RandomForestRegressor(),
            "XGBRegressor": XGBRegressor(),
            "GradientBoostingRegressor": GradientBoostingRegressor(),
            "LGBMRegressor": LGBMRegressor(),
            "KNeighborsRegressor": KNeighborsRegressor()
        }

        for model_name, model in models.items():
            model.fit(X_train, y_train)
            predictions = model.predict(X_test)
            mse = mean_squared_error(y_test, predictions)
            st.write(f"Model: {model_name}, MSE: {mse:.4f}")
            
            if best_score is None or mse < best_score:
                best_model = model
                best_score = mse
                best_model_name = model_name

        # Cross Validation with GridSearch for models that support n_estimators
        if isinstance(best_model, (RandomForestRegressor, XGBRegressor, GradientBoostingRegressor, LGBMRegressor)):
            grid_search = GridSearchCV(best_model, param_grid={"n_estimators": [50, 100, 150]}, cv=5)
            grid_search.fit(X_train, y_train)
            best_model = grid_search.best_estimator_

            # Evaluate with GridSearchCV results
            predictions = best_model.predict(X_test)
            mse = mean_squared_error(y_test, predictions)
            st.write(f"Best Model from GridSearch: {best_model_name}, MSE: {mse:.4f}")
    
    elif problem_type == "classification":
        models = {
            "LogisticRegression": LogisticRegression(solver='lbfgs'),
            "LogisticRegressionCV": LogisticRegressionCV(cv=5),
            "DecisionTreeClassifier": DecisionTreeClassifier(),
            "RandomForestClassifier": RandomForestClassifier(),
            "XGBClassifier": XGBClassifier(),
            "GradientBoostingClassifier": GradientBoostingClassifier(),
            "LGBMClassifier": LGBMClassifier(),
            "KNeighborsClassifier": KNeighborsClassifier()
        }

        best_model = None
        best_score = None
        best_model_name = ""
        
        for model_name, model in models.items():
            model.fit(X_train, y_train)
            predictions = model.predict(X_test)
            accuracy = accuracy_score(y_test, predictions)
            st.write(f"Model: {model_name}, Accuracy: {accuracy:.4f}")
            
            if best_score is None or accuracy > best_score:
                best_model = model
                best_score = accuracy
                best_model_name = model_name

        # Cross Validation with GridSearch for models that support n_estimators
        if isinstance(best_model, (RandomForestClassifier, XGBClassifier, GradientBoostingClassifier, LGBMClassifier)):
            grid_search = GridSearchCV(best_model, param_grid={"n_estimators": [50, 100, 150]}, cv=5)
            grid_search.fit(X_train, y_train)
            best_model = grid_search.best_estimator_

            # Evaluate with GridSearchCV results
            predictions = best_model.predict(X_test)
            accuracy = accuracy_score(y_test, predictions)
            st.write(f"Best Model from GridSearch: {best_model_name}, Accuracy: {accuracy:.4f}")

            
    
    # 爪转   转专 拽/MSE 砖
    st.write(f" **Best Model:** {best_model_name}")
    if problem_type == "regression":
        st.write(f" **Best Model MSE:** {best_score:.4f}")
    else:
        st.write(f" **Best Model Accuracy:** {best_score:.4f}")
    

    return best_model, X.columns









